{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "homework_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYFs9WYE3Fv7"
      },
      "source": [
        "# Q1: SIFT Keypoint Matching\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sged9HyI6I9"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQY4O82yJn-h"
      },
      "source": [
        "Contents of solution.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXOU_xa7ICbf"
      },
      "source": [
        "def RANSACFilter(\n",
        "        matched_pairs, keypoints1, keypoints2,\n",
        "        orient_agreement, scale_agreement):\n",
        "    \"\"\"\n",
        "    This function takes in `matched_pairs`, a list of matches in indices\n",
        "    and return a subset of the pairs using RANSAC.\n",
        "    Inputs:\n",
        "        matched_pairs: a list of tuples [(i, j)],\n",
        "            indicating keypoints1[i] is matched\n",
        "            with keypoints2[j]\n",
        "        keypoints1, 2: keypoints from image 1 and image 2\n",
        "            stored in np.array with shape (num_pts, 4)\n",
        "            each row: row, col, scale, orientation\n",
        "        *_agreement: thresholds for defining inliers, floats\n",
        "    Output:\n",
        "        largest_set: the largest consensus set in [(i, j)] format\n",
        "\n",
        "    HINTS: the \"*_agreement\" definitions are well-explained\n",
        "           in the assignment instructions.\n",
        "    \"\"\"\n",
        "    assert isinstance(matched_pairs, list)\n",
        "    assert isinstance(keypoints1, np.ndarray)\n",
        "    assert isinstance(keypoints2, np.ndarray)\n",
        "    assert isinstance(orient_agreement, float)\n",
        "    assert isinstance(scale_agreement, float)\n",
        "    ## START\n",
        "\n",
        "\n",
        "    ## END\n",
        "    assert isinstance(largest_set, list)\n",
        "    return largest_set\n",
        "\n",
        "\n",
        "\n",
        "def FindBestMatches(descriptors1, descriptors2, threshold):\n",
        "    \"\"\"\n",
        "    This function takes in descriptors of image 1 and image 2,\n",
        "    and find matches between them. See assignment instructions for details.\n",
        "    Inputs:\n",
        "        descriptors: a K-by-128 array, where each row gives a descriptor\n",
        "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
        "        values with unit length.\n",
        "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
        "                   divided by \"the distance to the second nearest neighbour\".\n",
        "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
        "    Outputs:\n",
        "        matched_pairs: a list in the form [(i, j)] where i and j means\n",
        "                       descriptors1[i] is matched with descriptors2[j].\n",
        "    \"\"\"\n",
        "    assert isinstance(descriptors1, np.ndarray)\n",
        "    assert isinstance(descriptors2, np.ndarray)\n",
        "    assert isinstance(threshold, float)\n",
        "    ## START\n",
        "    ## the following is just a placeholder to show you the output format\n",
        "    num = 5\n",
        "    matched_pairs = [[i, i] for i in range(num)]\n",
        "    ## END\n",
        "    return matched_pairs\n",
        "\n",
        "\n",
        "def KeypointProjection(xy_points, h):\n",
        "    \"\"\"\n",
        "    This function projects a list of points in the source image to the\n",
        "    reference image using a homography matrix `h`.\n",
        "    Inputs:\n",
        "        xy_points: numpy array, (num_points, 2)\n",
        "        h: numpy array, (3, 3), the homography matrix\n",
        "    Output:\n",
        "        xy_points_out: numpy array, (num_points, 2), input points in\n",
        "        the reference frame.\n",
        "    \"\"\"\n",
        "    assert isinstance(xy_points, np.ndarray)\n",
        "    assert isinstance(h, np.ndarray)\n",
        "    assert xy_points.shape[1] == 2\n",
        "    assert h.shape == (3, 3)\n",
        "\n",
        "    # START\n",
        "\n",
        "    # END\n",
        "    return xy_points_out\n",
        "\n",
        "def RANSACHomography(xy_src, xy_ref, num_iter, tol):\n",
        "    \"\"\"\n",
        "    Given matches of keyponit xy coordinates, perform RANSAC to obtain\n",
        "    the homography matrix. At each iteration, this function randomly\n",
        "    choose 4 matches from xy_src and xy_ref.  Compute the homography matrix\n",
        "    using the 4 matches.  Project all source \"xy_src\" keypoints to the\n",
        "    reference image.  Check how many projected keyponits are within a `tol`\n",
        "    radius to the coresponding xy_ref points (a.k.a. inliers).  During the\n",
        "    iterations, you should keep track of the iteration that yields the largest\n",
        "    inlier set. After the iterations, you should use the biggest inlier set to\n",
        "    compute the final homography matrix.\n",
        "    Inputs:\n",
        "        xy_src: a numpy array of xy coordinates, (num_matches, 2)\n",
        "        xy_ref: a numpy array of xy coordinates, (num_matches, 2)\n",
        "        num_iter: number of RANSAC iterations.\n",
        "        tol: float\n",
        "    Outputs:\n",
        "        h: The final homography matrix.\n",
        "    \"\"\"\n",
        "    assert isinstance(xy_src, np.ndarray)\n",
        "    assert isinstance(xy_ref, np.ndarray)\n",
        "    assert xy_src.shape == xy_ref.shape\n",
        "    assert xy_src.shape[1] == 2\n",
        "    assert isinstance(num_iter, int)\n",
        "    assert isinstance(tol, (int, float))\n",
        "    tol = tol*1.0\n",
        "\n",
        "    # START\n",
        "\n",
        "\n",
        "\n",
        "    # END\n",
        "    assert isinstance(h, np.ndarray)\n",
        "    assert h.shape == (3, 3)\n",
        "    return h\n",
        "\n",
        "\n",
        "def FindBestMatchesRANSAC(\n",
        "        keypoints1, keypoints2,\n",
        "        descriptors1, descriptors2, threshold,\n",
        "        orient_agreement, scale_agreement):\n",
        "    \"\"\"\n",
        "    Note: you do not need to change this function.\n",
        "    However, we recommend you to study this function carefully\n",
        "    to understand how each component interacts with each other.\n",
        "\n",
        "    This function find the best matches between two images using RANSAC.\n",
        "    Inputs:\n",
        "        keypoints1, 2: keypoints from image 1 and image 2\n",
        "            stored in np.array with shape (num_pts, 4)\n",
        "            each row: row, col, scale, orientation\n",
        "        descriptors1, 2: a K-by-128 array, where each row gives a descriptor\n",
        "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
        "        values with unit length.\n",
        "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
        "                   divided by \"the distance to the second nearest neighbour\".\n",
        "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
        "        orient_agreement: in degrees, say 30 degrees.\n",
        "        scale_agreement: in floating points, say 0.5\n",
        "    Outputs:\n",
        "        matched_pairs_ransac: a list in the form [(i, j)] where i and j means\n",
        "        descriptors1[i] is matched with descriptors2[j].\n",
        "    Detailed instructions are on the assignment website\n",
        "    \"\"\"\n",
        "    orient_agreement = float(orient_agreement)\n",
        "    assert isinstance(keypoints1, np.ndarray)\n",
        "    assert isinstance(keypoints2, np.ndarray)\n",
        "    assert isinstance(descriptors1, np.ndarray)\n",
        "    assert isinstance(descriptors2, np.ndarray)\n",
        "    assert isinstance(threshold, float)\n",
        "    assert isinstance(orient_agreement, float)\n",
        "    assert isinstance(scale_agreement, float)\n",
        "    matched_pairs = FindBestMatches(\n",
        "        descriptors1, descriptors2, threshold)\n",
        "    matched_pairs_ransac = RANSACFilter(\n",
        "        matched_pairs, keypoints1, keypoints2,\n",
        "        orient_agreement, scale_agreement)\n",
        "    return matched_pairs_ransac"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unQ_k46xI-9Z"
      },
      "source": [
        "import pickle as pkl\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "random.seed(1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ArdgE4JtaV"
      },
      "source": [
        "Contents of hw_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIUH0aKRHWz9"
      },
      "source": [
        "def MatchRANSAC(\n",
        "        image1, image2, ratio_thres, orient_agreement, scale_agreement):\n",
        "    \"\"\"\n",
        "    Read two images and their associated SIFT keypoints and descriptors.\n",
        "    Find matches between images based on acos distance.\n",
        "    Filter a subset of matches using RANSAC\n",
        "    Display the final matches.\n",
        "    HINT: See main_match.py on how to use this function.\n",
        "    \"\"\"\n",
        "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
        "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
        "\n",
        "    keypoints1 = np.stack(keypoints1, axis=0)\n",
        "    keypoints2 = np.stack(keypoints2, axis=0)\n",
        "    matched_pairs = FindBestMatchesRANSAC(\n",
        "        keypoints1, keypoints2,\n",
        "        descriptors1, descriptors2,\n",
        "        ratio_thres, orient_agreement, scale_agreement)\n",
        "    matched_pairs = [\n",
        "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
        "    assert len(matched_pairs) > 0, \"No match received\"\n",
        "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
        "    return im3\n",
        "\n",
        "\n",
        "def Match(image1, image2, ratio_thres):\n",
        "    \"\"\"\n",
        "    Read two images and their associated SIFT keypoints and descriptors.\n",
        "    Find matches between images based on acos distance.\n",
        "    Display the final matches.\n",
        "    HINT: See main_match.py on how to use this function.\n",
        "    \"\"\"\n",
        "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
        "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
        "\n",
        "    matched_pairs = FindBestMatches(\n",
        "        descriptors1, descriptors2, ratio_thres)\n",
        "    matched_pairs = [\n",
        "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
        "    assert len(matched_pairs) > 0, \"No match received\"\n",
        "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
        "    return im3\n",
        "\n",
        "\n",
        "def ReadKeys(image):\n",
        "    \"\"\"Input an image and its associated SIFT keypoints.\n",
        "\n",
        "    The argument image is the image file name (without an extension).\n",
        "    The image is read from the PGM format file image.pgm and the\n",
        "    keypoints are read from the file image.key.\n",
        "\n",
        "    ReadKeys returns the following 3 arguments:\n",
        "\n",
        "    image: the image (in PIL 'RGB' format)\n",
        "\n",
        "    keypoints: K-by-4 array, in which each row has the 4 values specifying\n",
        "    a keypoint (row, column, scale, orientation).  The orientation\n",
        "    is in the range [-PI, PI] radians.\n",
        "\n",
        "    descriptors: a K-by-128 array, where each row gives a descriptor\n",
        "    for one of the K keypoints.  The descriptor is a 1D array of 128\n",
        "    values with unit length.\n",
        "    \"\"\"\n",
        "    im = Image.open(image+'.pgm').convert('RGB')\n",
        "    keypoints = []\n",
        "    descriptors = []\n",
        "    first = True\n",
        "    with open(image+'.key','r') as f:\n",
        "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC,skipinitialspace = True)\n",
        "        descriptor = []\n",
        "        for row in reader:\n",
        "            if len(row) == 2:\n",
        "                assert first, \"Invalid keypoint file header.\"\n",
        "                assert row[1] == 128, \"Invalid keypoint descriptor length in header (should be 128).\"\n",
        "                count = row[0]\n",
        "                first = False\n",
        "            if len(row) == 4:\n",
        "                keypoints.append(np.array(row))\n",
        "            if len(row) == 20:\n",
        "                descriptor += row\n",
        "            if len(row) == 8:\n",
        "                descriptor += row\n",
        "                assert len(descriptor) == 128, \"Keypoint descriptor length invalid (should be 128).\"\n",
        "                #normalize the key to unit length\n",
        "                descriptor = np.array(descriptor)\n",
        "                descriptor = descriptor / math.sqrt(np.sum(np.power(descriptor,2)))\n",
        "                descriptors.append(descriptor)\n",
        "                descriptor = []\n",
        "    assert len(keypoints) == count, \"Incorrect total number of keypoints read.\"\n",
        "    print(\"Number of keypoints read:\", int(count))\n",
        "    descriptors = np.stack(descriptors, axis=0)\n",
        "    return [im,keypoints,descriptors]\n",
        "\n",
        "\n",
        "def AppendImages(im1, im2):\n",
        "    \"\"\"Create a new image that appends two images side-by-side.\n",
        "\n",
        "    The arguments, im1 and im2, are PIL images of type RGB\n",
        "    \"\"\"\n",
        "    im1cols, im1rows = im1.size\n",
        "    im2cols, im2rows = im2.size\n",
        "    im3 = Image.new('RGB', (im1cols+im2cols, max(im1rows,im2rows)))\n",
        "    im3.paste(im1,(0,0))\n",
        "    im3.paste(im2,(im1cols,0))\n",
        "    return im3\n",
        "\n",
        "def DisplayMatches(im1, im2, matched_pairs):\n",
        "    \"\"\"Display matches on a new image with the two input images placed side by side.\n",
        "\n",
        "    Arguments:\n",
        "     im1           1st image (in PIL 'RGB' format)\n",
        "     im2           2nd image (in PIL 'RGB' format)\n",
        "     matched_pairs list of matching keypoints, im1 to im2\n",
        "\n",
        "    Displays and returns a newly created image (in PIL 'RGB' format)\n",
        "    \"\"\"\n",
        "    im3 = AppendImages(im1,im2)\n",
        "    offset = im1.size[0]\n",
        "    draw = ImageDraw.Draw(im3)\n",
        "    for match in matched_pairs:\n",
        "        draw.line((match[0][1], match[0][0], offset+match[1][1], match[1][0]),fill=\"red\",width=2)\n",
        "    im3.show()\n",
        "    return im3\n",
        "\n",
        "\n",
        "def ReadData(fname):\n",
        "    \"\"\"\n",
        "    Given the fname, return the image, keypoints, and descriptors.\n",
        "    Note: the fname should be a path of the image, but with no extensions.\n",
        "    For example, '/my/path/ubc.png' should be '/my/path/ubc'\n",
        "    \"\"\"\n",
        "    with open(fname + '.pkl', 'rb') as f:\n",
        "        data = pkl.load(f)\n",
        "    im = Image.open(fname + '.png').convert('RGB')\n",
        "    keypoints = data['keypoints']\n",
        "    descriptors = data['descriptors']\n",
        "    return [im, keypoints, descriptors]\n",
        "\n",
        "\n",
        "def FindBestMatchesXY(im_src_path, im_ref_path, ratio_thres):\n",
        "    \"\"\"\n",
        "    This function takes two image paths, fetch the corresponding keypoints\n",
        "    of the two image paths, find the best matches between keypoints\n",
        "    and return the keypoint correspondances in xy coordinates.\n",
        "    Inputs:\n",
        "        im_src_path: the path of the source image.\n",
        "        im_ref_path: the path of the image considered as the reference frame.\n",
        "        ratio_thres: threshold for ratio test.\n",
        "    Outputs:\n",
        "        xy_src: numpy array, (matches, 2), xy coordinates of keypoints in source.\n",
        "        xy_ref: numpy array, (matches, 2), xy coordinates of keypoints in ref.\n",
        "    \"\"\"\n",
        "    assert isinstance(im_src_path, str)\n",
        "    assert isinstance(im_ref_path, str)\n",
        "    assert isinstance(ratio_thres, float)\n",
        "    _, keypoints1, descriptors1 = ReadData(im_src_path)\n",
        "    _, keypoints2, descriptors2 = ReadData(im_ref_path)\n",
        "    matches = list(FindBestMatches(descriptors1, descriptors2, ratio_thres))\n",
        "    matches = [(keypoints1[i1], keypoints2[i2]) for (i1, i2) in matches]\n",
        "\n",
        "    # Extract the xy of the matches\n",
        "    yx_src, yx_ref = zip(*[(match[0][:2], match[1][:2]) for match in matches])\n",
        "    xy_src = np.array(yx_src)[:, [1, 0]]  # yx to xy\n",
        "    xy_ref = np.array(yx_ref)[:, [1, 0]]\n",
        "    return xy_src, xy_ref\n",
        "\n",
        "\n",
        "def PrepareData(image_list, ratio_thres):\n",
        "    \"\"\"\n",
        "    This function takes in a list of image paths of interests;\n",
        "    Extracts the keypoints correspondance between the reference image and all other images.\n",
        "    The first image on the image_list is the reference image.\n",
        "    Note: there is no RANSAC performed.\n",
        "    Inputs:\n",
        "        image_list: a list of paths to the images (with no extensions)\n",
        "        ratio_thres: the threshold for doing the ratio test of keypoint correspondance.\n",
        "    Outputs:\n",
        "        xy_src_list: numpy array, (num_matches, 2)\n",
        "        xy_ref_list: numpy array, (num_matches, 2)\n",
        "        im_list: a list of np.array, where each np.array is an image.\n",
        "    \"\"\"\n",
        "    assert isinstance(image_list, list)\n",
        "    assert len(image_list) > 1, \"Need at leat two images to do stiching\"\n",
        "    assert isinstance(image_list[0], str)\n",
        "    assert isinstance(ratio_thres, float)\n",
        "    assert ratio_thres >= 0.0\n",
        "    assert ratio_thres <= 1.0\n",
        "\n",
        "    xy_src_list = []\n",
        "    xy_ref_list = []\n",
        "    ref_image = image_list[0]\n",
        "    image_list = image_list[1:]\n",
        "    for src_image in image_list:\n",
        "        xy_src, xy_ref = FindBestMatchesXY(\n",
        "            src_image, ref_image, ratio_thres)\n",
        "        if xy_src.shape[0] >= 4:\n",
        "            xy_src_list.append(xy_src)\n",
        "            xy_ref_list.append(xy_ref)\n",
        "\n",
        "    im_ref, _, _ = ReadData(ref_image)\n",
        "    im_list = [np.array(im_ref)] + [\n",
        "        np.array(ReadData(img)[0]) for img in image_list]\n",
        "    return xy_src_list, xy_ref_list, im_list\n",
        "\n",
        "\n",
        "def MergeWarppedImages(canvas_height, canvas_width, warp_list):\n",
        "    \"\"\"\n",
        "    Wrap a list of images in the reference frame into one canvas.\n",
        "    Note:\n",
        "        each image is a numpy array of shape (canvas_height, canvas_width, 3)\n",
        "        The first image in the warp_list is the reference image\n",
        "    \"\"\"\n",
        "    assert isinstance(canvas_height, int)\n",
        "    assert isinstance(canvas_width, int)\n",
        "    assert isinstance(warp_list, list)\n",
        "\n",
        "    canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
        "\n",
        "    im_ref = warp_list[0]  # reference image in reference frame\n",
        "    assert im_ref.dtype == np.uint8\n",
        "    canvas[:im_ref.shape[0], :im_ref.shape[1]] = im_ref\n",
        "    alpha = 0.5\n",
        "    for wrap in warp_list[1:]:\n",
        "        assert isinstance(wrap, np.ndarray)\n",
        "        assert wrap.shape == canvas.shape\n",
        "        assert wrap.dtype == np.uint8\n",
        "        mask_wrap = Image.fromarray(wrap).convert('L')\n",
        "        mask_wrap = np.array(mask_wrap) > 0\n",
        "\n",
        "        mask_canvas = Image.fromarray(canvas).convert('L')\n",
        "        mask_canvas = np.array(mask_canvas) > 0\n",
        "\n",
        "        mask_intersect = np.logical_and(mask_canvas, mask_wrap)\n",
        "\n",
        "        # blend in intersected area\n",
        "        canvas[mask_intersect] = (\n",
        "                alpha*canvas[mask_intersect] +\n",
        "                (1-alpha)*wrap[mask_intersect]).astype(np.uint8)\n",
        "        canvas[mask_intersect] = (\n",
        "                alpha*canvas[mask_intersect] +\n",
        "                (1-alpha)*wrap[mask_intersect]).astype(np.uint8)\n",
        "\n",
        "        # copy in non-interected area\n",
        "        mask_empty = np.logical_not(mask_intersect)\n",
        "        canvas[mask_empty] += wrap[mask_empty]\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def ProjectImages(\n",
        "        xy_src_list, xy_ref_list, im_list,\n",
        "        canvas_height, canvas_width, num_iter, tol):\n",
        "    \"\"\"\n",
        "    This function takes in a list of images, and the points correspondance between\n",
        "    the reference image and other images; computes the homography from every source\n",
        "    image to the reference image using RANSAC; warp each source image to the reference\n",
        "    image frame using each homography computed.\n",
        "    Inputs:\n",
        "        xy_src_list: a list of np array, each element is keypoint correspondance\n",
        "                     between a source image to the reference image, in xy coordinates.\n",
        "        xy_ref_list: a list of np array, each element is keypoint correspondance\n",
        "                     between a source image to the reference image, in xy coordinates.\n",
        "        im_list: all images in np.array form, the firs element is the reference image.\n",
        "        canvas_height, canvas_width: the dimension of the canvas to copy the warps over.\n",
        "        num_iter: number of RANSAC iterations in RANSACHomography\n",
        "        tol: the Euclidean tolerance for keypoints matching projection.\n",
        "    Outputs:\n",
        "        A list of images in np.array form after they have been projected to\n",
        "        the reference frame.\n",
        "    \"\"\"\n",
        "    assert isinstance(xy_src_list, list)\n",
        "    assert isinstance(xy_ref_list, list)\n",
        "    assert isinstance(im_list, list)\n",
        "    assert isinstance(canvas_height, int)\n",
        "    assert isinstance(canvas_width, int)\n",
        "    assert isinstance(num_iter, int)\n",
        "    assert isinstance(tol, (int, float))\n",
        "    assert len(xy_src_list) == len(xy_ref_list)\n",
        "    assert len(xy_src_list) + 1 == len(im_list), \\\n",
        "        \"Num of source images + 1 == num of all images\"\n",
        "\n",
        "    homo_list = []\n",
        "    for xy_src, xy_ref in zip(xy_src_list, xy_ref_list):\n",
        "        h = RANSACHomography(xy_src, xy_ref, num_iter, tol)\n",
        "        homo_list.append(h)\n",
        "    warp_list = [im_list[0]]\n",
        "    im_list = im_list[1:]\n",
        "    assert len(im_list) == len(homo_list)\n",
        "    for im, h in zip(im_list, homo_list):\n",
        "        result = cv2.warpPerspective(im, h, (canvas_width, canvas_height))\n",
        "        warp_list.append(result)\n",
        "    return warp_list\n",
        "\n",
        "\n",
        "def VisualizePointProj(xy_src, xy_ref, xy_proj, im_src, im_ref):\n",
        "    assert isinstance(xy_src, np.ndarray)\n",
        "    assert isinstance(xy_ref, np.ndarray)\n",
        "    assert isinstance(xy_proj, np.ndarray)\n",
        "    assert isinstance(im_src, np.ndarray)\n",
        "    assert isinstance(im_ref, np.ndarray)\n",
        "    assert xy_src.shape == xy_ref.shape\n",
        "    assert xy_src.shape == xy_proj.shape\n",
        "\n",
        "    fig, axes = plt.subplots(\n",
        "        1, 2, figsize=(30, 30), gridspec_kw={'width_ratios': [1, 2]})\n",
        "    for xy_a, xy_b in zip(xy_proj, xy_ref):\n",
        "        x1, y1 = xy_a\n",
        "        x2, y2 = xy_b\n",
        "        axes[1].plot([x1, x2],[y1, y2], 'w-', linewidth=2)\n",
        "\n",
        "    axes[0].imshow(im_src)\n",
        "    axes[0].scatter(xy_src[:, 0], xy_src[:, 1], c='#fafba4', s=100, marker='.')\n",
        "    axes[0].title.set_text('Source Image')\n",
        "\n",
        "    axes[1].imshow(im_ref)\n",
        "    axes[1].scatter(xy_proj[:, 0], xy_proj[:, 1], c='#fafba4', s=100, marker='.')\n",
        "    axes[1].scatter(xy_ref[:, 0], xy_ref[:, 1], c='#d63447', s=100, marker='.')\n",
        "    axes[1].title.set_text('Reference Image')\n",
        "    fig.show()\n",
        "    input('Press any key to exit the program')\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzQZRfl3RtZ"
      },
      "source": [
        "This sample program loads two images and their invariant keypoints and then draws 5 lines between randomly selected keypoints to show how matches can be displayed. Your task is to improve this program so that it identifies and displays correct matches by comparing the keypoint descriptor vectors. Note: Your program should find all possible matches, not just 5 as shown in this sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tixo62_JHwH"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHD7yayBPYHu"
      },
      "source": [
        "Contents of main_match.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-03-08T05:43:54.912Z"
        },
        "id": "4OMbTaWr2Kvw"
      },
      "source": [
        "# Test run matching with no ransac\n",
        "plt.figure(figsize=(20, 20))\n",
        "im = Match('./data/scene', './data/basmati', ratio_thres=0.6)\n",
        "plt.title('Match')\n",
        "plt.imshow(im)\n",
        "\n",
        "# Test run matching with ransac\n",
        "plt.figure(figsize=(20, 20))\n",
        "im = MatchRANSAC(\n",
        "    './data/scene', './data/basmati',\n",
        "    ratio_thres=0.6, orient_agreement=30, scale_agreement=0.5)\n",
        "plt.title('MatchRANSAC')\n",
        "plt.imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9YyRs6-PMwU"
      },
      "source": [
        "# Q2: Panorama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6cWw4TuPOHH"
      },
      "source": [
        "import os.path as op"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8rfVMtjPwfi"
      },
      "source": [
        "Contents of test_pano.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOr0ks-oPtAK"
      },
      "source": [
        "path = './data/'\n",
        "image_list = ['Hanging1', 'Hanging2']\n",
        "image_list = [op.join(path, im) for im in image_list]\n",
        "# the dimension of the canvas (numpy array)\n",
        "# to which we are copying images.\n",
        "canvas_width = 1000\n",
        "canvas_height = 600\n",
        "\n",
        "# some precomputed data for sanity check\n",
        "with open('./data/test.pkl', 'rb') as f:\n",
        "    test_dict = pkl.load(f)\n",
        "h_gt = test_dict['h']  # the homograph matrix we computed\n",
        "\n",
        "# matches between the source and the refence image\n",
        "xy_src = test_dict['xy_src']  # (match, 2)\n",
        "xy_ref = test_dict['xy_ref']  # (match, 2)\n",
        "\n",
        "# image_list should store both the reference and the source images\n",
        "ref_image = image_list[0]  # first element is the reference image\n",
        "source_image = image_list[1]\n",
        "\n",
        "# compute the homography matrix to transform the source to the reference\n",
        "h, _ = cv2.findHomography(xy_src, xy_ref)\n",
        "\n",
        "# The current computed value should equal to our precomputed one\n",
        "norm_diff = ((h-h_gt)**2).sum()\n",
        "assert norm_diff < 1e-7, 'The computed homography matrix should equal to the given one.'\n",
        "\n",
        "# read the two images as numpy arrays\n",
        "im_src = np.array(ReadData(source_image)[0])\n",
        "im_ref = np.array(ReadData(ref_image)[0])\n",
        "\n",
        "# project source image to the reference image using the homography matrix\n",
        "# the size of canvas is specified to store all images after projections.\n",
        "im_src_warp = cv2.warpPerspective(im_src, h, (canvas_width, canvas_height))\n",
        "\n",
        "# warp_list should contain all images, where the first\n",
        "# element is the reference image\n",
        "warp_list = [im_ref, im_src_warp]\n",
        "result = MergeWarppedImages(canvas_height, canvas_width, warp_list)\n",
        "\n",
        "# plot the result of the warping\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(result)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788xdwZ2Qgw-"
      },
      "source": [
        "import sys"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_6mwVDaQbmC"
      },
      "source": [
        "Contents of main_proj.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH_3-KgiQc1p"
      },
      "source": [
        "with open('./data/test.pkl', 'rb') as f:\n",
        "    test_dict = pkl.load(f)\n",
        "\n",
        "# visualize 30 random matches\n",
        "num_pts = 30\n",
        "idx = np.random.permutation(test_dict['xy_src'].shape[0])[:num_pts]\n",
        "xy_src = test_dict['xy_src'][idx]\n",
        "xy_ref = test_dict['xy_ref'][idx]\n",
        "h = test_dict['h']\n",
        "\n",
        "# project the src keypoints to the reference frame using homography\n",
        "xy_proj = KeypointProjection(xy_src, h)\n",
        "\n",
        "# visualize the results\n",
        "im_ref = np.array(Image.open('./data/Hanging1.png'))\n",
        "im_src = np.array(Image.open('./data/Hanging2.png'))\n",
        "VisualizePointProj(xy_src, xy_ref, xy_proj, im_src, im_ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MKuuMTURbNW"
      },
      "source": [
        "Contents of main_pano.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1u30M7Qkh3"
      },
      "source": [
        "def create_pano(\n",
        "        image_list, ratio_thres,\n",
        "        canvas_height, canvas_width,\n",
        "        num_iter, tol, figsize=(20, 20)):\n",
        "    \"\"\"\n",
        "    This function creates a panorama using a list of images.\n",
        "    Inputs:\n",
        "        image_list: a list of str, the path to each image (without file extensions).\n",
        "        ratio_thres: the ratio test threshold in `FindBestMatches`\n",
        "        canvas_height, canvas_width: The dimension of the canvas\n",
        "        num_iter: num of iterations of performing RANSAC to find the homography matrix.\n",
        "        tol: tolerance for keypoint projection\n",
        "    \"\"\"\n",
        "    # Get the matches from `FindBestMatches`\n",
        "    # xy_src_list: np.array, (matches, 2) in xy format\n",
        "    # xy_ref_list: np.array, (matches, 2) in xy format\n",
        "    # im_list: a list of images in np.array\n",
        "    xy_src_list, xy_ref_list, im_list = PrepareData(\n",
        "        image_list, ratio_thres)\n",
        "\n",
        "    # Use the matches to estimate a homography matrix to the ref image frame\n",
        "    # for each source image. Then project each source image to the reference\n",
        "    # frame using the homography matrix.\n",
        "    wrap_list = ProjectImages(\n",
        "        xy_src_list, xy_ref_list, im_list,\n",
        "        canvas_height, canvas_width, num_iter, tol)\n",
        "\n",
        "    # Merge the projected images above\n",
        "    # Note: the first element is the reference image in warp_list\n",
        "    result = MergeWarppedImages(\n",
        "        canvas_height, canvas_width, wrap_list)\n",
        "\n",
        "    # show the final panorama\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(result)\n",
        "    plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ReUFdyRdYD"
      },
      "source": [
        "path = './data/'\n",
        "\n",
        "canvas_height = 600\n",
        "canvas_width = 1000\n",
        "image_list = ['Rainier1', 'Rainier2', 'Rainier3','Rainier4','Rainier5','Rainier6']\n",
        "\n",
        "num_iter = 50\n",
        "tol = 10\n",
        "ratio_thres = 0.9\n",
        "image_list = [op.join(path, im) for im in image_list]\n",
        "create_pano(image_list, ratio_thres, canvas_height, canvas_width,\n",
        "            num_iter, tol, figsize=(20, 20))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}